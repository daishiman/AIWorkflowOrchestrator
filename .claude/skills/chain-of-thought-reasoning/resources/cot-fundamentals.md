# Chain-of-Thought 基礎理論

## 概要

Chain-of-Thought（CoT）推論は、大規模言語モデルの
推論能力を引き出す重要なプロンプティング技法です。

## 理論的背景

### CoTの定義

```
Chain-of-Thought =
  問題を受け取り、最終回答に至るまでの
  中間的な推論ステップを明示的に生成すること
```

### 従来のプロンプティングとの違い

**標準プロンプティング**:

```
入力: 問題
     ↓ [ブラックボックス]
出力: 回答
```

**Chain-of-Thought**:

```
入力: 問題
     ↓
思考1: [最初の分析]
     ↓
思考2: [次のステップ]
     ↓
思考3: [さらなる推論]
     ↓
出力: 回答
```

## なぜCoTが機能するか

### 1. 問題分解の促進

複雑な問題を小さな管理可能なステップに分解

```
複雑な問題
├─ サブ問題1 → 中間結果1
├─ サブ問題2 → 中間結果2
└─ サブ問題3 → 中間結果3
                  ↓
              最終回答
```

### 2. 作業メモリの拡張

LLMの限られた「作業メモリ」を補完

```
従来: [問題] → [内部処理のみ] → [回答]

CoT:  [問題] → [思考1を出力] → 思考1を参照 →
              → [思考2を出力] → 思考1,2を参照 →
              → [回答を出力]
```

### 3. 注意メカニズムの活用

生成されたテキストが以降の生成に影響

```
"まず、Aを考えると..."
      ↓
  [Aの考察がコンテキストに追加]
      ↓
"次に、Aを踏まえてBを..."
      ↓
  [論理的に整合した推論が継続]
```

### 4. 自己モニタリングの強化

明示的な推論により誤りを検出しやすくなる

```
ステップ1: 5 × 3 = 15 ✓
ステップ2: 15 + 2 = 17 ✓
ステップ3: 17 ÷ 4 = 4.25 ✓
→ 各ステップで検証可能
```

## CoTの効果が高いタスク

### 高い効果が期待できるタスク

| タスク     | 効果       | 理由                   |
| ---------- | ---------- | ---------------------- |
| 算術推論   | 非常に高い | 多段階計算の追跡       |
| 論理推論   | 非常に高い | 論理的ステップの明示化 |
| 常識推論   | 高い       | 暗黙の知識の活性化     |
| 記号推論   | 高い       | ルール適用の追跡       |
| コード生成 | 中〜高     | 論理構造の明確化       |

### 効果が限定的なタスク

| タスク     | 効果 | 理由                     |
| ---------- | ---- | ------------------------ |
| 事実の回答 | 低い | 推論不要                 |
| 単純分類   | 低い | 直感的判断で十分         |
| 創作・生成 | 低い | 論理的推論が主目的でない |
| 翻訳       | 低い | パターンマッチング主体   |

## CoTの限界

### 1. トークンコストの増加

```yaml
comparison:
  standard_prompt:
    input: 50 tokens
    output: 10 tokens
    total: 60 tokens

  cot_prompt:
    input: 50 tokens
    output: 100-200 tokens
    total: 150-250 tokens
```

### 2. 正しい推論の保証なし

```
CoTは推論を「見せる」が「正しくする」わけではない

例:
ステップ1: 正しい
ステップ2: 誤り ← ここで間違うと
ステップ3: ステップ2に基づく（誤り）
結論: 誤り
```

### 3. 単純タスクでの過剰処理

```
質問: 1 + 1 = ?

過剰なCoT:
"まず、加算の定義を考えましょう。
 1は自然数の最小値で..."

適切な回答:
"2"
```

## モデルサイズとCoTの関係

### 創発的な能力

```
モデルサイズと CoT効果の関係:

小規模モデル (< 10B): CoT効果なし〜逆効果
中規模モデル (10-50B): 効果が現れ始める
大規模モデル (> 50B): 顕著な効果
超大規模モデル (> 100B): 複雑な推論も可能
```

### 閾値効果

```
精度
  ↑
  │              ┌────── CoTあり
  │             /
  │            /
  │           /
  │    ┌─────/───────── CoTなし
  │   /
  │  /
  └──────────────────────→ モデルサイズ
     小規模    中規模    大規模
```

## CoTのバリエーション

### 1. Zero-Shot CoT

```markdown
特徴: 例示なし、トリガーフレーズのみ
用途: 汎用的な推論タスク
効率: 高い（プロンプトが短い）
精度: 中程度
```

### 2. Few-Shot CoT

```markdown
特徴: 推論例を含む
用途: 特定形式の推論タスク
効率: 中程度（例示分のトークン）
精度: 高い
```

### 3. Self-Consistency

```markdown
特徴: 複数回推論して多数決
用途: 高精度要求タスク
効率: 低い（複数回実行）
精度: 非常に高い
```

### 4. Tree of Thoughts

```markdown
特徴: 分岐と探索
用途: 複雑な問題探索
効率: 非常に低い
精度: 複雑な問題で高い
```

### 5. Program-of-Thoughts

```markdown
特徴: コード生成による推論
用途: 数学・計算タスク
効率: 中程度
精度: 数学問題で非常に高い
```

## 研究の発展

### 主要な論文

```yaml
foundational:
  - title: "Chain-of-Thought Prompting Elicits Reasoning"
    authors: "Wei et al., 2022"
    contribution: "CoTの基本概念を確立"

  - title: "Large Language Models are Zero-Shot Reasoners"
    authors: "Kojima et al., 2022"
    contribution: "Zero-Shot CoTの発見"

  - title: "Self-Consistency Improves Chain of Thought"
    authors: "Wang et al., 2022"
    contribution: "Self-Consistency手法の提案"

  - title: "Tree of Thoughts"
    authors: "Yao et al., 2023"
    contribution: "探索的推論の拡張"
```

### 発展の方向性

```
CoTの進化:
├─ より効率的なプロンプティング
├─ 自動的なCoT生成
├─ マルチモーダルCoT
├─ 検証メカニズムの統合
└─ ドメイン特化のCoTパターン
```

## 実践への示唆

### CoTを使うべき時

1. **推論の透明性が必要**:
   - 監査可能性が求められる
   - エラーの原因特定が重要

2. **複雑な多段階タスク**:
   - 単一ステップで解けない
   - 中間結果の追跡が必要

3. **精度向上が優先**:
   - トークンコストより精度
   - 重要な意思決定支援

### CoTを避けるべき時

1. **単純なタスク**:
   - 直接的な回答で十分
   - 推論が過剰になる

2. **レイテンシが重要**:
   - リアルタイム応答が必要
   - トークンコストが制約

3. **創作タスク**:
   - 論理的推論が主目的でない
   - 自由な発想が重要
